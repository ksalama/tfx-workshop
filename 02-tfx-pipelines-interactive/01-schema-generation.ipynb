{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Schema Generation with TFDV\n",
    "\n",
    "In this lab, we use [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv) (TFDV) to perform the following:\n",
    "\n",
    "1. **Generate statistics** from the training data.\n",
    "2. **Visualise and analyse** the generated statistics.\n",
    "2. **Infer** a **schema** from the generated statistics.\n",
    "3. **Update** the schema with domain knowledge.\n",
    "4. **Validate** the evaluation data against the schema.\n",
    "5. **Save** the schema for later use.\n",
    "\n",
    "\n",
    "<br/>\n",
    "<img valign=\"middle\" src=\"imgs/tfdv.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used in these labs is the **UCI Adult Dataset**: https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "It is a classification dataset, where the task is to predict whether income exceeds 50K USD per yearr based on census data. It is also known as \"Census Income\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.io import gfile\n",
    "\n",
    "WORKSPACE = 'workspace' # you can set to a GCS location\n",
    "DATA_DIR = os.path.join(WORKSPACE, 'data')\n",
    "RAW_SCHEMA_DIR = os.path.join(WORKSPACE, 'raw_schema')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gfile.exists(WORKSPACE):\n",
    "    print(\"Removing previous workspace...\")\n",
    "    gfile.rmtree(WORKSPACE)\n",
    "\n",
    "print(\"Creating new workspace...\")\n",
    "gfile.mkdir(WORKSPACE)\n",
    "print(\"Creating data directory...\")\n",
    "gfile.mkdir(DATA_DIR)\n",
    "\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR,'train.csv')\n",
    "EVAL_DATA_FILE = os.path.join(DATA_DIR,'eval.csv')\n",
    "\n",
    "print(\"Downloading raw data...\")\n",
    "gfile.copy(src='gs://cloud-samples-data/ml-engine/census/data/adult.data.csv', dst=os.path.join(DATA_DIR,'file1.csv'))\n",
    "gfile.copy(src='gs://cloud-samples-data/ml-engine/census/data/adult.test.csv', dst=os.path.join(DATA_DIR,'file2.csv'))\n",
    "print(\"Data downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adding headers to the CSV files as the CsvExampleGen components expect headers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HEADER = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "               'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "               'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "               'native_country', 'income_bracket']\n",
    "\n",
    "pd.read_csv(DATA_DIR +\"/file1.csv\", names=HEADER).to_csv(DATA_DIR +\"/train-01.csv\", index=False)\n",
    "pd.read_csv(DATA_DIR +\"/file2.csv\", names=HEADER).to_csv(DATA_DIR +\"/train-02.csv\", index=False)\n",
    "gfile.remove(DATA_DIR +\"/file1.csv\")\n",
    "gfile.remove(DATA_DIR +\"/file2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l $DATA_DIR/train-01.csv\n",
    "!head $DATA_DIR/train-01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_BUCKET = 'ksalama-ocado-gcs'\n",
    "!gsutil -m cp $DATA_DIR/*.csv gs://$GCS_BUCKET/data/census/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $DATA_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Data Validation for Schema Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "TARGET_FEATURE_NAME = 'income_bracket'\n",
    "WEIGHT_FEATURE_NAME = 'fnlwgt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = tfdv.generate_statistics_from_csv(\n",
    "    data_location=DATA_DIR+'/*.csv', \n",
    "    column_names=None, # CSV data file include header\n",
    "    stats_options=tfdv.StatsOptions(\n",
    "        weight_feature=WEIGHT_FEATURE_NAME,\n",
    "        sample_rate=1.0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Infer Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.infer_schema(statistics=train_stats)\n",
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Alter the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relax the minimum fraction of values that must come from the domain for feature occupation.\n",
    "occupation = tfdv.get_feature(schema, 'occupation')\n",
    "occupation.distribution_constraints.min_domain_mass = 0.9\n",
    "\n",
    "# Add new value to the domain of feature native_country.\n",
    "native_country_domain = tfdv.get_domain(schema, 'native_country')\n",
    "native_country_domain.value.append('Egypt')\n",
    "\n",
    "# All features are by default in both TRAINING and SERVING environments.\n",
    "schema.default_environment.append('TRAINING')\n",
    "schema.default_environment.append('EVALUATION')\n",
    "schema.default_environment.append('SERVING')\n",
    "\n",
    "# Specify that the class feature is not in SERVING environment.\n",
    "tfdv.get_feature(schema, TARGET_FEATURE_NAME).not_in_environment.append('SERVING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(RAW_SCHEMA_DIR):\n",
    "    shutil.rmtree(RAW_SCHEMA_DIR)\n",
    "    \n",
    "os.mkdir(RAW_SCHEMA_DIR)\n",
    "\n",
    "raw_schema_location = os.path.join(RAW_SCHEMA_DIR, 'schema.pbtxt')\n",
    "tfdv.write_schema_text(schema, raw_schema_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loading saved schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.load_schema_text(raw_schema_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
