{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with TensorFlow Extended (TFX) Pipelines\n",
    "1. Extracting the new training data from the source using [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) component.\n",
    "2. Validating new training data\n",
    "    * Generating statistics from the the incoming data using [StatisticsGen](https://www.tensorflow.org/tfx/guide/statsgen) component.\n",
    "    * Importing a fixed raw schema using [ImporterNode](https://github.com/tensorflow/tfx/blob/master/tfx/components/common_nodes/importer_node.py) component.\n",
    "    * Validating data based on the schema using [ExampleValidator](https://www.tensorflow.org/tfx/guide/exampleval) component.\n",
    "5. Transforming the data for ML using the [Transform](https://www.tensorflow.org/tfx/guide/transform) component.\n",
    "6. Training the model using the [Trainer](https://www.tensorflow.org/tfx/guide/trainer) component.\n",
    "7. Evaluate the model using the [Evaluator](https://www.tensorflow.org/tfx/guide/evaluator) component.\n",
    "8. Validate the model using a [Custom TFX](https://www.tensorflow.org/tfx/guide/custom_component) component.\n",
    "9. Push the the blessed model to serving locationusing [Pusher](https://www.tensorflow.org/tfx/guide/pusher) component.\n",
    "10. Query the [ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tfx\n",
    "import tensorflow as tf\n",
    "import tensorflow.io as tf_io\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"TFX Version:\", tfx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = 'workspace'\n",
    "DATA_DIR = WORKSPACE + '/data'\n",
    "RAW_SCHEMA_DIR = WORKSPACE + '/raw_schema'\n",
    "OUTPUT_DIR = WORKSPACE + '/artifacts'\n",
    "\n",
    "REMOVE_ARTIFACTS = True\n",
    "if REMOVE_ARTIFACTS:\n",
    "    print(\"Removing previous artifacts...\")\n",
    "    tf_io.gfile.rmtree(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Create Interactive Context\n",
    "This will use an ephemeral SQLite MLMD connection contained in the pipeline_root directory with file name \"metadata.sqlite\" will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "PIPELINE_NAME = 'tfx-census-classification'\n",
    "\n",
    "context = InteractiveContext(\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    pipeline_root=OUTPUT_DIR,\n",
    "    metadata_connection_config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(\"Standard Artifact types:\")\n",
    "pprint([a for a in dir(tfx.types.standard_artifacts) if a[0].isupper()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion (ExampleGen)\n",
    "1. Reads the CSV data files (expecting to include headers)\n",
    "2. Split the data to train and eval sets\n",
    "3. Write the data to TFRecords\n",
    "\n",
    "\n",
    "* **Inputs**: ExternalPath\n",
    "* **Ouptpus**: Examples (TFRecords)\n",
    "* **Properties**: split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.proto import example_gen_pb2\n",
    "\n",
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=4),\n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "    ]))\n",
    "\n",
    "\n",
    "example_gen = tfx.components.CsvExampleGen(\n",
    "    instance_name='Data_Extraction_Spliting',\n",
    "    input=external_input(DATA_DIR),\n",
    "    output_config=output_config\n",
    ")\n",
    "\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample of the extracted data...\n",
    "Since TTF v1.15 is used, you need to enable eager execution. However, this causes problems to subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ = False\n",
    "\n",
    "if READ:\n",
    "    tf.enable_eager_execution()\n",
    "\n",
    "    import tensorflow_data_validation as tfdv\n",
    "\n",
    "    train_uri = example_gen.outputs['examples'].get()[0].uri\n",
    "\n",
    "    tfrecord_filenames = tf.data.Dataset.list_files(train_uri+\"*\")\n",
    "\n",
    "    # Create a `TFRecordDataset` to read these files\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "    # Iterate over the first 3 records and decode them using a TFExampleDecoder\n",
    "    for tfrecord in dataset.take(3):\n",
    "        serialized_example = tfrecord.numpy()\n",
    "        example = tfdv.TFExampleDecoder().decode(serialized_example)\n",
    "        pprint(example)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Validation\n",
    "1. Generate the **statistics** for the data to validate.\n",
    "2. Import the **raw_schema** created in the Data Analysis phase.\n",
    "3. Validat the **statistics** against the schema and generate **anomalies** (if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Generating statistics for the data to validate (StatisticsGen)\n",
    "* **Inputs**: Examples\n",
    "* **Outputs**: ExampleStatistics\n",
    "* **Properries**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = tfx.components.StatisticsGen(\n",
    "    instance_name='Statistics_Generation',\n",
    "    examples=example_gen.outputs['examples'])\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Import the fixed raw schema (ImporterNode)\n",
    "The **ImporterNode** allows you to import an external artifact to a component.\n",
    "You need to specifiy:\n",
    "1. Artifact Type\n",
    "2. Artifcat Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_importer = tfx.components.common_nodes.importer_node.ImporterNode(\n",
    "    instance_name='Schema_Importer',\n",
    "    source_uri=RAW_SCHEMA_DIR,\n",
    "    artifact_type=tfx.types.standard_artifacts.Schema,\n",
    "    reimport=False\n",
    ")\n",
    "\n",
    "context.run(schema_importer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(schema_importer.outputs['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Validate the input data statistics (ExampleValidator)\n",
    "* **Inputs**: ExampleStatistics, Schema\n",
    "* **Outputs**: ExampleAnomalies (if any)\n",
    "* **Properties**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    instance_name=\"Data_Validation\"\n",
    ")\n",
    "\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Implement the preprocessing logic\n",
    "\n",
    "We need to implement the preprocessing logic in a python module: **transform.py**.\n",
    "\n",
    "* This module is expected to have **preprocessing_fn** method, which accepts a dictionary of the raw features, and returns a dictionary of the transformed features.\n",
    "* We use the **raw schema** to identify feature types and the required transformation.\n",
    "* The function is implemented using [TensorFlow Transform](https://www.tensorflow.org/tfx/guide/tft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tranform train and eval data (Transform)\n",
    "\n",
    "The component uses the transform output generated from transforming the train data to transform eval data.\n",
    "That is, while the train data is **analyzed** and **transformed**, the eval data is **only transformed** uaing the output of the analyze phase (TransformGraph) on the train data.\n",
    "\n",
    "* **Inputs**: train and eval data (Examples), raw schema (Schema), transformation module (file)\n",
    "* **outputs**: transformed train and eval data (Examples), transform output (TransformGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "_transform_module_file = 'modules/transform.py'\n",
    "\n",
    "transform = tfx.components.Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    module_file=_transform_module_file,\n",
    "    instance_name=\"Data_Transformation\"\n",
    ")\n",
    "\n",
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = transform.outputs['transform_graph'].get()[0].uri\n",
    "os.listdir(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample of the transformed data\n",
    "Since TTF v1.15 is used, you need to enable eager execution. However, this causes problems to subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ = False\n",
    "\n",
    "if READ:\n",
    "    tf.enable_eager_execution()\n",
    "\n",
    "    train_uri = transform.outputs['transformed_examples'].get()[1].uri\n",
    "    tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                          for name in os.listdir(train_uri)]\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "    decoder = tfdv.TFExampleDecoder()\n",
    "    for tfrecord in dataset.take(3):\n",
    "        serialized_example = tfrecord.numpy()\n",
    "        example = decoder.decode(serialized_example)\n",
    "        pprint(example)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model (Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Implement a train Python module.\n",
    "\n",
    "Create a Python module containing a **trainer_fn** function, which must return an estimator.\n",
    "\n",
    "The **trainer_fn** receives the following parameters:\n",
    "* hparams: currently includes train_steps, eval_steps, and transform_output.\n",
    "* schema: the raw data schema. This is used to create the serving input function to export the model.\n",
    "\n",
    "The **trainer_fn** returns a dictionary of the following:\n",
    "* estimator: The estimator that will be used for training and eval.\n",
    "* train_spec: Spec for training.\n",
    "* eval_spec: Spec for eval.\n",
    "* eval_input_receiver_fn: Input function for eval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train the model using the Trainer component\n",
    "* **Inputs**: train module file with the **trainer_fn**, raw schema (Schema), and transform output (TransformGraph)\n",
    "* **Outputs**: saved_model (Model)\n",
    "* **Properties**: train and eval args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "_train_module_file = 'modules/train.py'\n",
    "\n",
    "trainer = tfx.components.Trainer(\n",
    "    module_file=_train_module_file,\n",
    "    transformed_examples=transform.outputs['transformed_examples'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    train_args=tfx.proto.trainer_pb2.TrainArgs(num_steps=1000),\n",
    "    eval_args=tfx.proto.trainer_pb2.EvalArgs(num_steps=None),\n",
    "    instance_name='Census_Classifier_Trainer'\n",
    ")\n",
    "\n",
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = trainer.outputs['model'].get()[0].uri\n",
    "serving_model_path = os.path.join(train_uri, 'serving_model_dir', 'export', 'census')\n",
    "latest_serving_model_path = os.path.join(serving_model_path, max(os.listdir(serving_model_path)))\n",
    "print(latest_serving_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the trained model (Evaluator)\n",
    "* **Inputs**: eval data (Examples), trained model (Model)\n",
    "* **Outputs** eval metric (ModelEvaluation)\n",
    "* **Properties**: Slicing Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_slicing_spec=tfx.proto.evaluator_pb2.FeatureSlicingSpec(\n",
    "    specs=[\n",
    "        tfx.proto.evaluator_pb2.SingleSlicingSpec(),\n",
    "        tfx.proto.evaluator_pb2.SingleSlicingSpec(column_for_slicing=['occupation'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model_analyzer = tfx.components.Evaluator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model=trainer.outputs['model'],\n",
    "    feature_slicing_spec=feature_slicing_spec,\n",
    "    instance_name=\"Occupation_based_Evaluator\"\n",
    ")\n",
    "\n",
    "context.run(model_analyzer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "results_uri = model_analyzer.outputs['output'].get()[0].uri\n",
    "tfma.load_eval_result(results_uri).slicing_metrics[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a Custom TFX Component that validates the trained model based on its produced evaluation metric.\n",
    "\n",
    "The custom validator will **bless** the model if:\n",
    "1. Overal accuracy is greater than 85%.\n",
    "2. Accuracy per **Occupation** slice is at most 10% less than the overall accuracy.\n",
    "\n",
    "* **Inputs**: Evaluation Metric (ModelEvaluation), trained model (Model)\n",
    "* **Outputs**: blessing (ModelBlessing)\n",
    "* **Properties**: accuracy_threshold, slice_accuracy_tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Create ComponentSepc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.types import standard_artifacts\n",
    "from tfx.types.component_spec import ChannelParameter\n",
    "from tfx.types.component_spec import ExecutionParameter\n",
    "\n",
    "class AccuracyValidatorSpec(tfx.types.ComponentSpec):\n",
    "    \n",
    "    INPUTS = {\n",
    "        'eval_results': ChannelParameter(type=standard_artifacts.ModelEvaluation),\n",
    "        'model': ChannelParameter(type=standard_artifacts.Model),\n",
    "    }\n",
    "    \n",
    "    OUTPUTS = {\n",
    "      'blessing': ChannelParameter(type=standard_artifacts.ModelBlessing),\n",
    "    }\n",
    "    \n",
    "    PARAMETERS = {\n",
    "        'accuracy_threshold': ExecutionParameter(type=float),\n",
    "        'slice_accuracy_tolerance': ExecutionParameter(type=float),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Create Custom Exectutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components.base import base_executor\n",
    "from tfx.types import artifact_utils\n",
    "from tfx.utils import io_utils\n",
    "\n",
    "class AccuracyValidatorExecutor(base_executor.BaseExecutor):\n",
    "    \n",
    "    def Do(self, input_dict, output_dict, exec_properties):\n",
    "        \n",
    "        valid = True\n",
    "        \n",
    "        self._log_startup(input_dict, output_dict, exec_properties)\n",
    "        \n",
    "        accuracy_threshold = exec_properties['accuracy_threshold']\n",
    "        slice_accuracy_tolerance = exec_properties['slice_accuracy_tolerance']\n",
    "        min_slice_accuracy = accuracy_threshold - slice_accuracy_tolerance\n",
    "        print(\"Accuracy Threshold:\", accuracy_threshold)\n",
    "        print(\"Slice Accuracy Tolerance:\", slice_accuracy_tolerance)\n",
    "        print(\"Min Accuracy per Slice:\", min_slice_accuracy)\n",
    "        \n",
    "        results_uri = input_dict['eval_results'][0].uri\n",
    "        eval_results = tfma.load_eval_result(results_uri)\n",
    "        \n",
    "        overall_acc = eval_results.slicing_metrics[0][1]['']['']['accuracy']['doubleValue']\n",
    "        print(\"Overall accuracy:\", overall_acc)\n",
    "        \n",
    "        if overall_acc >= accuracy_threshold:\n",
    "            for slicing_metric in eval_results.slicing_metrics:\n",
    "                slice_acc = slicing_metric[1]['']['']['accuracy']['doubleValue']\n",
    "                if slice_acc < min_slice_accuracy:\n",
    "                    print(\"Slice accuracy value < min accuracy:\", slice_acc )\n",
    "                    valid = False\n",
    "                    break\n",
    "        else:\n",
    "            valid = False\n",
    "        \n",
    "        print(\"Valid:\", valid)\n",
    "        \n",
    "        blessing = artifact_utils.get_single_instance(output_dict['blessing'])\n",
    "        \n",
    "        # Current model.\n",
    "        current_model = artifact_utils.get_single_instance(input_dict['model'])\n",
    "        blessing.set_string_custom_property('current_model', current_model.uri)\n",
    "        blessing.set_int_custom_property('current_model_id', current_model.id)\n",
    "\n",
    "        if valid:\n",
    "            io_utils.write_string_file(os.path.join(blessing.uri, 'BLESSED'), '')\n",
    "            blessing.set_int_custom_property('blessed', 1)\n",
    "        else:\n",
    "            io_utils.write_string_file(os.path.join(blessing.uri, 'NOT_BLESSED'), '')\n",
    "            blessing.set_int_custom_property('blessed', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Create AccuracyModelValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from tfx import types\n",
    "from tfx.components.base import base_component\n",
    "from tfx.components.base import executor_spec\n",
    "\n",
    "class AccuracyModelValidator(base_component.BaseComponent):\n",
    "\n",
    "    SPEC_CLASS = AccuracyValidatorSpec\n",
    "    EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(AccuracyValidatorExecutor)\n",
    "    \n",
    "    def __init__(self,\n",
    "                 eval_results: types.channel,\n",
    "                 model: types.channel,\n",
    "                 accuracy_threshold: float,\n",
    "                 slice_accuracy_tolerance: float,\n",
    "                 blessing: Optional[types.Channel] = None,\n",
    "                 instance_name=None):\n",
    "        \n",
    "        blessing = blessing or types.Channel(\n",
    "            type=standard_artifacts.ModelBlessing,\n",
    "            artifacts=[standard_artifacts.ModelBlessing()])\n",
    "        \n",
    "        spec = AccuracyValidatorSpec(\n",
    "            eval_results=eval_results, model=model, blessing=blessing, \n",
    "            accuracy_threshold=accuracy_threshold, slice_accuracy_tolerance=slice_accuracy_tolerance\n",
    "        )\n",
    "        \n",
    "        super().__init__(spec=spec, instance_name=instance_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_model_validator = AccuracyModelValidator(\n",
    "    eval_results=model_analyzer.outputs['output'],\n",
    "    model=trainer.outputs['model'],\n",
    "    accuracy_threshold=0.75,\n",
    "    slice_accuracy_tolerance=0.15,\n",
    "    instance_name=\"Accuracy_Model_Validator\"\n",
    ")\n",
    "\n",
    "context.run(accuracy_model_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blessing_uri = accuracy_model_validator.outputs.blessing.get()[0].uri\n",
    "!ls -l {blessing_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pushing the Blessed Model (Pusher)\n",
    "This steps pushes the validated and blessed model to its final destination. This could be:\n",
    "1. A Model Registry\n",
    "2. Git Repository\n",
    "3. API Serving Platform\n",
    "4. A specific filesystem location\n",
    "5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Push the blessed model to model registry (filesystem location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_models_location = WORKSPACE + '/model_registry'\n",
    "!mkdir {serving_models_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_destination=tfx.proto.pusher_pb2.PushDestination(\n",
    "    filesystem=tfx.proto.pusher_pb2.PushDestination.Filesystem(\n",
    "        base_directory=serving_models_location)\n",
    ")\n",
    "\n",
    "pusher = tfx.components.Pusher(\n",
    "    model=trainer.outputs['model'],\n",
    "    model_blessing=accuracy_model_validator.outputs['blessing'],\n",
    "    push_destination=push_destination\n",
    ")\n",
    "\n",
    "context.run(pusher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Test the pushed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_serving_model_path = os.path.join(serving_models_location, max(os.listdir(serving_models_location)))\n",
    "print(latest_serving_model_path)\n",
    "!saved_model_cli show --dir={latest_serving_model_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "    export_dir = latest_serving_model_path,\n",
    "    signature_def_key=\"predict\"\n",
    ")\n",
    "print(\"\")\n",
    "\n",
    "output = predictor_fn(\n",
    "    {\n",
    "        'age': [34.0],\n",
    "        'workclass': ['Private'],\n",
    "        'education': ['Doctorate'],\n",
    "        'education_num': [10.0],\n",
    "        'marital_status': ['Married-civ-spouse'],\n",
    "        'occupation': ['Prof-specialty'],\n",
    "        'relationship': ['Husband'],\n",
    "        'race': ['White'],\n",
    "        'gender': ['Male'],\n",
    "        'capital_gain': [0.0], \n",
    "        'capital_loss': [0.0], \n",
    "        'hours_per_week': [40.0],\n",
    "        'native_country':['Egyptian']\n",
    "    }\n",
    ")\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Querying Metadata database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(os.path.join(OUTPUT_DIR, 'metadata.sqlite'))\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Artifact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM Artifact;\")\n",
    "for entry in cursor.fetchall():\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
