{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "This is a prerequisite to the subsequent labs. In this Notebook, we download the [Census dataset](https://archive.ics.uci.edu/ml/datasets/adult) to your local directory or a Cloud Storage location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.io import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = 'workspace' # you can set to a GCS location\n",
    "DATA_DIR = os.path.join(WORKSPACE, 'raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create workspace and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gfile.exists(WORKSPACE):\n",
    "    print(\"Removing previous workspace...\")\n",
    "    gfile.rmtree(WORKSPACE)\n",
    "\n",
    "print(\"Creating new workspace...\")\n",
    "gfile.mkdir(WORKSPACE)\n",
    "print(\"Creating data directory...\")\n",
    "gfile.mkdir(DATA_DIR)\n",
    "\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR,'train.csv')\n",
    "EVAL_DATA_FILE = os.path.join(DATA_DIR,'eval.csv')\n",
    "\n",
    "print(\"Downloading raw data...\")\n",
    "gfile.copy(src='gs://cloud-samples-data/ml-engine/census/data/adult.data.csv', dst=TRAIN_DATA_FILE)\n",
    "gfile.copy(src='gs://cloud-samples-data/ml-engine/census/data/adult.test.csv', dst=EVAL_DATA_FILE)\n",
    "print(\"Data downloaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gcsfs # required if your data files in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HEADER = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "               'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "               'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "               'native_country', 'income_bracket']\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_DATA_FILE, names=HEADER)\n",
    "print(\"Instance count: {}\".format(len(train_data)))\n",
    "train_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: TFDV\n",
    "Data Analysis and Schema Generation with TensorFlow Data Validation (TFDV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
