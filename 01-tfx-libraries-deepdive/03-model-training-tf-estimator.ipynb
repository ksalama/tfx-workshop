{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation with Estimator API\n",
    "In this lan, we use the [TensorFlow Estimator API](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) to build, train, and evaluate a [DNNLinearCombinedClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedClassifier). This lab covers the following:\n",
    "1. Implement a data **input_fn** using **transform schema**\n",
    "2. Create **feature columns** using **transform schema**\n",
    "3. Instantiate a premade **DNNCombinedClassifier**\n",
    "4. **Train** and **evaluate** the model.\n",
    "5. **Export** the model for **serving**.\n",
    "\n",
    "<br/>\n",
    "<img valign=\"middle\" src=\"imgs/tf-estimator.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.15.0\n",
      "TFDV version: 0.15.0\n",
      "TFT version: 0.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.io as tf_io\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "print('TF version: {}'.format(tf.__version__))\n",
    "print('TFDV version: {}'.format(tfdv.__version__))\n",
    "print('TFT version: {}'.format(tft.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = 'workspace' # you can set to a GCS location\n",
    "TRANSFORMED_DATA_DIR = os.path.join(WORKSPACE, 'transformed_data')\n",
    "TRANSFORM_ARTEFACTS_DIR = os.path.join(WORKSPACE, 'transform_artifacts')\n",
    "TRANSFORMED_TRAIN_DATA_FILE = os.path.join(TRANSFORMED_DATA_DIR,'train-*.tfrecords')\n",
    "TRANSFORMED_EVAL_DATA_FILE = os.path.join(TRANSFORMED_DATA_DIR,'eval-*.tfrecords')\n",
    "RAW_SCHEMA_LOCATION = os.path.join(WORKSPACE, 'raw_schema.pbtxt')\n",
    "MODELS_DIR = os.path.join(WORKSPACE, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFT Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output = tft.TFTransformOutput(TRANSFORM_ARTEFACTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement TFRecords Input function\n",
    "* Use [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) APIs: **list_files()**, **skip()**, **map()**, **filter()**, **batch()**, **shuffle()**, **repeat()**, **prefetch()**, **cache()**, etc.\n",
    "* Use [tf.data.experimental.make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset) to read and parse CSV data files.\n",
    "* Use [tf.data.experimental.make_batched_features_dataset](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_batched_features_dataset) to read and parse TFRecords data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(tfrecords_files, \n",
    "                  batch_size, num_epochs=1, shuffle=False):\n",
    "   \n",
    "    def input_fn():\n",
    "        dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "            file_pattern=tfrecords_files,\n",
    "            batch_size=batch_size,\n",
    "            features=transform_output.transformed_feature_spec(),\n",
    "            label_key=TARGET_FEATURE_NAME,\n",
    "            reader=tf.data.TFRecordDataset,\n",
    "            num_epochs=num_epochs,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Feature Columns\n",
    "\n",
    "<br/>\n",
    "<img valign=\"middle\" src=\"imgs/feature-columns.png\" width=\"800\">\n",
    "\n",
    "Base feature columns\n",
    "  1. [numeric_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column|)\n",
    "  2. [categorical_column_with_vocabulary_list](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list)\n",
    "  3. [categorical_column_with_vocabulary_file](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file)\n",
    "  4. [categorical_column_with_identity](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_identity)\n",
    "  5. [categorical_column_with_hash_buckets](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_hash_bucket)\n",
    "\n",
    "Extended feature columns\n",
    "  1. [bucketized_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column)\n",
    "  2. [indicator_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column)\n",
    "  3. [crossing_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/crossed_column)\n",
    "  4. [embedding_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = 'income_bracket'\n",
    "TARGET_LABELS = [' <=50K', ' >50K']\n",
    "WEIGHT_COLUMN_NAME = 'fnlwgt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating featuer columns can be **meta-data** driven, with the help of the **stransform schema**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def create_feature_columns():\n",
    "    \n",
    "    wide_columns = []\n",
    "    deep_columns = []\n",
    "    \n",
    "    transformed_features = transform_output.transformed_metadata.schema.feature\n",
    "\n",
    "    for feature in transformed_features:\n",
    "        if feature.name in [TARGET_FEATURE_NAME, WEIGHT_COLUMN_NAME]:\n",
    "            continue\n",
    "\n",
    "        # Categorical features\n",
    "        if hasattr(feature, 'int_domain') and feature.int_domain.is_categorical:\n",
    "            vocab_size = feature.int_domain.max + 1\n",
    "            \n",
    "            # Create a categotical feature column with identity\n",
    "            categorical_feature_column = tf.feature_column.categorical_column_with_identity(\n",
    "                feature.name, num_buckets=vocab_size\n",
    "            )\n",
    "            \n",
    "            wide_columns.append(categorical_feature_column)\n",
    "            \n",
    "            \n",
    "            # Create embedding column\n",
    "            embedding_feature_column = tf.feature_column.embedding_column(\n",
    "                categorical_feature_column, \n",
    "                dimension = int(math.sqrt(vocab_size))\n",
    "            )\n",
    "            \n",
    "            deep_columns.append(embedding_feature_column)\n",
    "            \n",
    "        \n",
    "        # Numeric features\n",
    "        else:\n",
    "            deep_columns.append(\n",
    "                tf.feature_column.numeric_column(feature.name))\n",
    "            \n",
    "    # Create crossing feature\n",
    "    education_X_occupation = tf.feature_column.crossed_column(\n",
    "        ['education_integerized', 'workclass_integerized'], hash_bucket_size=int(1e4))\n",
    "    wide_columns.append(education_X_occupation)\n",
    "\n",
    "        # Create embeddings for crossing column.\n",
    "    education_X_occupation_embedded = tf.feature_column.embedding_column(\n",
    "        education_X_occupation, dimension=10)\n",
    "    deep_columns.append(education_X_occupation_embedded)\n",
    "    \n",
    "    return wide_columns, deep_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide, deep = create_feature_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instantiate an [Wide and Deep Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedClassifier)\n",
    "1. An ML model that combines **generalization** (deep part) and **memorization** (wide part).\n",
    "2. **Categorical** (sparse) features are feed into the **wide** part, while **numerical** (dense) features are feed into **deep** part.\n",
    "3. You can make use of different representation of the same feature in both parts:\n",
    "    1. **Categorical** features can be **embedded**, and feed into **deep** part.\n",
    "    2. **Numerical** features can be **bucketized**, and feed into **wide** part.\n",
    "    \n",
    "See [Wide & Deep Learning: Better Together with TensorFlow](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html) blog post for more details.\n",
    "\n",
    "![alt text](imgs/wide-n-deep.png \"Wide \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement adaptive learning rate\n",
    "* [exponential_decay](https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay)\n",
    "* [consine_decay](https://www.tensorflow.org/api_docs/python/tf/train/cosine_decay)\n",
    "* [linear_cosine_decay](https://www.tensorflow.org/api_docs/python/tf/train/linear_cosine_decay)\n",
    "* [consine_decay_restarts](https://www.tensorflow.org/api_docs/python/tf/train/cosine_decay_restarts)\n",
    "* [polynomial decay](https://www.tensorflow.org/api_docs/python/tf/train/polynomial_decay)\n",
    "* [piecewise_constant_decay](https://www.tensorflow.org/api_docs/python/tf/train/piecewise_constant_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(initial_learning_rate, decay_steps):\n",
    "    learning_rate = tf.train.cosine_decay_restarts(\n",
    "        initial_learning_rate,\n",
    "        tf.train.get_global_step(),\n",
    "        first_decay_steps=50,\n",
    "        t_mul=2.0,\n",
    "        m_mul=1.0,\n",
    "        alpha=0.0,\n",
    "    )\n",
    "    \n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    return tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an evaluation metric\n",
    "* [tf.metrics](https://www.tensorflow.org/api_docs/python/tf/metrics)\n",
    "* [tf.estimator.add_metric](https://www.tensorflow.org/api_docs/python/tf/estimator/add_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn(labels, predictions):\n",
    "    \n",
    "    metrics = {}\n",
    "    label_index = tf.contrib.lookup.index_table_from_tensor(tf.constant(TARGET_LABELS)).lookup(labels)\n",
    "    one_hot_labels = tf.one_hot(label_index, len(TARGET_LABELS))\n",
    "    \n",
    "    metrics['mirco_accuracy'] = tf.metrics.mean_per_class_accuracy(\n",
    "        labels=label_index,\n",
    "        predictions=predictions['class_ids'],\n",
    "        num_classes=2\n",
    "    )\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(params, run_config):\n",
    "    \n",
    "    wide_columns, deep_columns = create_feature_columns()\n",
    "    \n",
    "    estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "\n",
    "        n_classes=len(TARGET_LABELS),\n",
    "        label_vocabulary=TARGET_LABELS,\n",
    "        weight_column=WEIGHT_COLUMN_NAME,\n",
    "\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_optimizer=lambda: update_optimizer(\n",
    "            params.learning_rate, params.max_steps),\n",
    "#         dnn_optimizer=tf.train.AdamOptimizer(\n",
    "#           learning_rate=params.learning_rate),\n",
    "        dnn_hidden_units=params.hidden_units,\n",
    "        dnn_dropout=params.dropout,\n",
    "        dnn_activation_fn=tf.nn.relu,\n",
    "        batch_norm=True,\n",
    "\n",
    "        linear_feature_columns=wide_columns,\n",
    "        linear_optimizer='Ftrl',\n",
    "\n",
    "        config=run_config\n",
    "    )\n",
    "    \n",
    "    estimator = tf.estimator.add_metrics(\n",
    "        estimator, metric_fn)\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run a Train and Evaluate Experiment\n",
    "**Delete** the **model_dir** file if you don't want a **Warm Start**\n",
    "* If not deleted, and you **alter** the model, it will error.\n",
    "\n",
    "[TrainSpec](https://www.tensorflow.org/api_docs/python/tf/estimator/TrainSpec)\n",
    "* Set **shuffle** in the **input_fn** to **True**\n",
    "* Set **num_epochs** in the **input_fn** to **None**\n",
    "* Set **max_steps**. One batch (feed-forward pass & backpropagation) \n",
    "corresponds to 1 training step. \n",
    "\n",
    "[EvalSpec](https://www.tensorflow.org/api_docs/python/tf/estimator/EvalSpec)\n",
    "* Set **shuffle** in the **input_fn** to **False**\n",
    "* Set Set **num_epochs** in the **input_fn** to **1**\n",
    "* Set **steps** to **None** if you want to use all the evaluation data. \n",
    "* Otherwise, set **steps** to the number of batches you want to use for evaluation, and set **shuffle** to True.\n",
    "* Set **start_delay_secs** to 0  to start evaluation as soon as a checkpoint is produced.\n",
    "* Set **throttle_secs** to 0 to re-evaluate as soon as a new checkpoint is produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Implement an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(estimator, params, run_config, \n",
    "                   resume=False, train_hooks=None):\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    if not resume: \n",
    "        if tf_io.gfile.exists(run_config.model_dir):\n",
    "            print(\"Removing previous model checkpoints...\")\n",
    "            tf_io.gfile.rmtree(run_config.model_dir)\n",
    "    else:\n",
    "        print(\"Resuming training...\")\n",
    "\n",
    "    # Create train specs.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = make_input_fn(\n",
    "            TRANSFORMED_TRAIN_DATA_FILE,\n",
    "            batch_size=params.batch_size,\n",
    "            num_epochs=None, # Run until the max_steps is reached.\n",
    "            shuffle=True\n",
    "        ),\n",
    "        max_steps=params.max_steps,\n",
    "        hooks=train_hooks\n",
    "    )\n",
    "\n",
    "    # Create eval specs.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = make_input_fn(\n",
    "            TRANSFORMED_EVAL_DATA_FILE,\n",
    "            batch_size=params.batch_size, \n",
    "        ),\n",
    "        exporters=None, # This can be set to export a saved model \n",
    "        start_delay_secs=0,\n",
    "        throttle_secs=0,\n",
    "        steps=None # Set to limit number of steps for evaluation.\n",
    "    )\n",
    "  \n",
    "\n",
    "    print(\"Experiment started...\")\n",
    "    print(\".......................................\")\n",
    "  \n",
    "    # Run train and evaluate.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator,\n",
    "        train_spec=train_spec, \n",
    "        eval_spec=eval_spec\n",
    "    )\n",
    "\n",
    "    print(\".......................................\")\n",
    "    print(\"Experiment finished.\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters and run_config.\n",
    "\n",
    "* Set **model_dir** in the **run_config**\n",
    "* If the data **size is known**, training **steps**, with respect to **epochs** would be: **(training_size / batch_size) * epochs** \n",
    "* By default, a **checkpoint** is saved every 600 secs.  That is, the model is **evaluated** only every 10mins. \n",
    "* To change this behaviour, set one of the following parameters in the **run_config**\n",
    " * **save_checkpoints_secs**: Save checkpoints every this many **seconds**.\n",
    " * **save_checkpoints_steps**: Save checkpoints every this many **steps**.\n",
    "* Set the number of the checkpoints to keep using **keep_checkpoint_max**\n",
    "* Set **train_distribute** and/or **eval_dsitribute** strategy for Multi-GPU training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 19820610\n",
    "\n",
    "class Parameters():\n",
    "    pass\n",
    "\n",
    "MODEL_NAME = 'dnn_classifier'\n",
    "MODEL_DIR = os.path.join(MODELS_DIR, MODEL_NAME)\n",
    "\n",
    "TRAIN_DATA_SIZE = 32561\n",
    "\n",
    "params = Parameters()\n",
    "params.learning_rate = 0.001\n",
    "params.hidden_units = [128, 128, 128]\n",
    "params.dropout = 0.15\n",
    "params.batch_size =  128\n",
    "\n",
    "# Set number of steps with respect to epochs.\n",
    "epochs = 1000\n",
    "steps_per_epoch = int(math.ceil(TRAIN_DATA_SIZE / params.batch_size))\n",
    "params.max_steps = steps_per_epoch * epochs\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    tf_random_seed=RANDOM_SEED,\n",
    "    save_checkpoints_steps=steps_per_epoch, # Save a checkpoint after each epoch, evaluate the model after each epoch.\n",
    "    keep_checkpoint_max=3, # Keep the 3 most recently  produced checkpoints.\n",
    "    model_dir=MODEL_DIR,\n",
    "    save_summary_steps=100, # Summary steps for Tensorboard.\n",
    "    log_step_count_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Run experiment with early stopping hook\n",
    "* [stop_if_higher_hook](https://www.google.com/search?q=stop_if_higher_hook&oq=stop_if_higher_hook) \n",
    "* [stop_if_lower_hook](https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/stop_if_lower_hook) \n",
    "* [stop_if_no_increase_hook](https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/stop_if_no_increase_hook)\n",
    "* [stop_if_no_decrease_hook](https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/stop_if_no_decrease_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_save_checkpoints_steps': 255, '_master': '', '_session_creation_timeout_secs': 7200, '_eval_distribute': None, '_num_worker_replicas': 1, '_experimental_distribute': None, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_protocol': None, '_keep_checkpoint_max': 3, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa4ec69e240>, '_tf_random_seed': 19820610, '_train_distribute': None, '_evaluation_master': '', '_save_checkpoints_secs': None, '_task_type': 'worker', '_model_dir': 'workspace/models/dnn_classifier', '_service': None, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_is_chief': True, '_experimental_max_worker_delay_secs': None, '_save_summary_steps': 100, '_device_fn': None}\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_save_checkpoints_steps': 255, '_task_type': 'worker', '_session_creation_timeout_secs': 7200, '_eval_distribute': None, '_num_worker_replicas': 1, '_experimental_distribute': None, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_protocol': None, '_keep_checkpoint_max': 3, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa4ec69e048>, '_tf_random_seed': 19820610, '_train_distribute': None, '_evaluation_master': '', '_save_checkpoints_secs': None, '_master': '', '_model_dir': 'workspace/models/dnn_classifier', '_service': None, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_is_chief': True, '_experimental_max_worker_delay_secs': None, '_save_summary_steps': 100, '_device_fn': None}\n",
      "Removing previous model checkpoints...\n",
      "Experiment started...\n",
      ".......................................\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 255 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/data/experimental/ops/readers.py:890: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/data/experimental/ops/readers.py:214: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3079: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3079: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/canned/head.py:398: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 22528306.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 25.9716\n",
      "INFO:tensorflow:loss = 13340354.0, step = 51 (1.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.565\n",
      "INFO:tensorflow:loss = 9354753.0, step = 101 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.733\n",
      "INFO:tensorflow:loss = 7465516.0, step = 151 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.271\n",
      "INFO:tensorflow:loss = 9252200.0, step = 201 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.912\n",
      "INFO:tensorflow:loss = 9730506.0, step = 251 (0.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 255 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:49:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-255\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:49:06\n",
      "INFO:tensorflow:Saving dict for global step 255: accuracy = 0.76861805, accuracy_baseline = 0.7638036, auc = 0.8896199, auc_precision_recall = 0.7294555, average_loss = 0.47445467, global_step = 255, label/mean = 0.23619643, loss = 11429766.0, mirco_accuracy = 0.5111834, precision = 1.0, prediction/mean = 0.17123577, recall = 0.020383513\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 255: workspace/models/dnn_classifier/model.ckpt-255\n",
      "INFO:tensorflow:global_step/sec: 5.65448\n",
      "INFO:tensorflow:loss = 6236916.0, step = 301 (8.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.164\n",
      "INFO:tensorflow:loss = 8891303.0, step = 351 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.782\n",
      "INFO:tensorflow:loss = 6740119.0, step = 401 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.824\n",
      "INFO:tensorflow:loss = 9776212.0, step = 451 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.474\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/summary/summary_iterator.py:68: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:loss = 5872060.0, step = 501 (0.508 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 510 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:49:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-510\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:49:17\n",
      "INFO:tensorflow:Saving dict for global step 510: accuracy = 0.770314, accuracy_baseline = 0.7638036, auc = 0.90488493, auc_precision_recall = 0.7595916, average_loss = 0.4519099, global_step = 510, label/mean = 0.23619643, loss = 10886655.0, mirco_accuracy = 0.5155645, precision = 0.988315, prediction/mean = 0.14095362, recall = 0.02789326\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 510: workspace/models/dnn_classifier/model.ckpt-510\n",
      "INFO:tensorflow:global_step/sec: 6.10171\n",
      "INFO:tensorflow:loss = 7399517.0, step = 551 (8.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.19\n",
      "INFO:tensorflow:loss = 9278636.0, step = 601 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.795\n",
      "INFO:tensorflow:loss = 7405168.5, step = 651 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.298\n",
      "INFO:tensorflow:loss = 7196300.5, step = 701 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.224\n",
      "INFO:tensorflow:loss = 5984755.0, step = 751 (0.445 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 765 into workspace/models/dnn_classifier/model.ckpt.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:49:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-765\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:49:27\n",
      "INFO:tensorflow:Saving dict for global step 765: accuracy = 0.7777948, accuracy_baseline = 0.7638036, auc = 0.906513, auc_precision_recall = 0.76350015, average_loss = 0.4213563, global_step = 765, label/mean = 0.23619643, loss = 10150609.0, mirco_accuracy = 0.5293486, precision = 0.9944939, prediction/mean = 0.14709876, recall = 0.059565235\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 765: workspace/models/dnn_classifier/model.ckpt-765\n",
      "INFO:tensorflow:global_step/sec: 6.27501\n",
      "INFO:tensorflow:loss = 6930675.0, step = 801 (7.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.09\n",
      "INFO:tensorflow:loss = 9066570.0, step = 851 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.201\n",
      "INFO:tensorflow:loss = 7376443.0, step = 901 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.393\n",
      "INFO:tensorflow:loss = 7815527.0, step = 951 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.582\n",
      "INFO:tensorflow:loss = 6626261.0, step = 1001 (0.512 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1020 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:49:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-1020\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:49:37\n",
      "INFO:tensorflow:Saving dict for global step 1020: accuracy = 0.78934145, accuracy_baseline = 0.7638036, auc = 0.9114927, auc_precision_recall = 0.7759889, average_loss = 0.3867638, global_step = 1020, label/mean = 0.23619643, loss = 9317265.0, mirco_accuracy = 0.5538952, precision = 0.9869058, prediction/mean = 0.15035279, recall = 0.109575726\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1020: workspace/models/dnn_classifier/model.ckpt-1020\n",
      "INFO:tensorflow:global_step/sec: 5.8915\n",
      "INFO:tensorflow:loss = 8128877.0, step = 1051 (8.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.292\n",
      "INFO:tensorflow:loss = 9216112.0, step = 1101 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.871\n",
      "INFO:tensorflow:loss = 8735832.0, step = 1151 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.688\n",
      "INFO:tensorflow:loss = 7879411.5, step = 1201 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.686\n",
      "INFO:tensorflow:loss = 7102569.5, step = 1251 (0.451 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1275 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:49:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-1275\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:49:47\n",
      "INFO:tensorflow:Saving dict for global step 1275: accuracy = 0.8010783, accuracy_baseline = 0.7638036, auc = 0.9129238, auc_precision_recall = 0.779421, average_loss = 0.36740118, global_step = 1275, label/mean = 0.23619643, loss = 8850813.0, mirco_accuracy = 0.57977027, precision = 0.969552, prediction/mean = 0.16075179, recall = 0.16292913\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1275: workspace/models/dnn_classifier/model.ckpt-1275\n",
      "INFO:tensorflow:global_step/sec: 6.41042\n",
      "INFO:tensorflow:loss = 8551848.0, step = 1301 (7.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.178\n",
      "INFO:tensorflow:loss = 7071317.0, step = 1351 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.159\n",
      "INFO:tensorflow:loss = 6339927.0, step = 1401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.986\n",
      "INFO:tensorflow:loss = 8900838.0, step = 1451 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.361\n",
      "INFO:tensorflow:loss = 7944264.0, step = 1501 (0.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1530 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:49:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-1530\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:49:57\n",
      "INFO:tensorflow:Saving dict for global step 1530: accuracy = 0.8088849, accuracy_baseline = 0.7638036, auc = 0.9133321, auc_precision_recall = 0.7807961, average_loss = 0.35455716, global_step = 1530, label/mean = 0.23619643, loss = 8541396.0, mirco_accuracy = 0.59790206, precision = 0.9505313, prediction/mean = 0.16920047, recall = 0.20134255\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1530: workspace/models/dnn_classifier/model.ckpt-1530\n",
      "INFO:tensorflow:global_step/sec: 6.05398\n",
      "INFO:tensorflow:loss = 6760564.5, step = 1551 (8.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.565\n",
      "INFO:tensorflow:loss = 9059300.0, step = 1601 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.929\n",
      "INFO:tensorflow:loss = 7710528.5, step = 1651 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.422\n",
      "INFO:tensorflow:loss = 9841975.0, step = 1701 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.769\n",
      "INFO:tensorflow:loss = 6976460.0, step = 1751 (0.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1785 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:50:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-1785\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:50:07\n",
      "INFO:tensorflow:Saving dict for global step 1785: accuracy = 0.8381296, accuracy_baseline = 0.7638036, auc = 0.91125035, auc_precision_recall = 0.77946365, average_loss = 0.33204657, global_step = 1785, label/mean = 0.23619643, loss = 7999109.0, mirco_accuracy = 0.67163324, precision = 0.8880138, prediction/mean = 0.19102764, recall = 0.36009005\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1785: workspace/models/dnn_classifier/model.ckpt-1785\n",
      "INFO:tensorflow:global_step/sec: 5.95431\n",
      "INFO:tensorflow:loss = 7400646.0, step = 1801 (8.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.958\n",
      "INFO:tensorflow:loss = 10277022.0, step = 1851 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.1\n",
      "INFO:tensorflow:loss = 6777786.0, step = 1901 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.426\n",
      "INFO:tensorflow:loss = 11025546.0, step = 1951 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.495\n",
      "INFO:tensorflow:loss = 8505970.0, step = 2001 (0.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2040 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:50:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-2040\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:50:17\n",
      "INFO:tensorflow:Saving dict for global step 2040: accuracy = 0.83350766, accuracy_baseline = 0.7638036, auc = 0.91282034, auc_precision_recall = 0.78090245, average_loss = 0.3374074, global_step = 2040, label/mean = 0.23619643, loss = 8128253.0, mirco_accuracy = 0.65782887, precision = 0.9014911, prediction/mean = 0.16557503, recall = 0.33131438\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2040: workspace/models/dnn_classifier/model.ckpt-2040\n",
      "INFO:tensorflow:global_step/sec: 6.31082\n",
      "INFO:tensorflow:loss = 7059047.0, step = 2051 (7.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.035\n",
      "INFO:tensorflow:loss = 7055906.5, step = 2101 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.46\n",
      "INFO:tensorflow:loss = 5493010.0, step = 2151 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.548\n",
      "INFO:tensorflow:loss = 8780403.0, step = 2201 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.967\n",
      "INFO:tensorflow:loss = 7172730.0, step = 2251 (0.434 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2295 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:50:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-2295\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:50:27\n",
      "INFO:tensorflow:Saving dict for global step 2295: accuracy = 0.845234, accuracy_baseline = 0.7638036, auc = 0.91430044, auc_precision_recall = 0.78386724, average_loss = 0.32046092, global_step = 2295, label/mean = 0.23619643, loss = 7720007.0, mirco_accuracy = 0.69544005, precision = 0.85819834, prediction/mean = 0.19219904, recall = 0.41299874\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2295: workspace/models/dnn_classifier/model.ckpt-2295\n",
      "INFO:tensorflow:global_step/sec: 6.09843\n",
      "INFO:tensorflow:loss = 6493192.5, step = 2301 (8.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.164\n",
      "INFO:tensorflow:loss = 8153054.0, step = 2351 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.773\n",
      "INFO:tensorflow:loss = 5836203.5, step = 2401 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.26\n",
      "INFO:tensorflow:loss = 8690958.0, step = 2451 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.96\n",
      "INFO:tensorflow:No increase in metric \"accuracy\" for 255 steps, which is greater than or equal to max steps (100) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 2501\n",
      "INFO:tensorflow:loss = 8140835.0, step = 2501 (0.580 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into workspace/models/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T12:50:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from workspace/models/dnn_classifier/model.ckpt-2501\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-12:50:37\n",
      "INFO:tensorflow:Saving dict for global step 2501: accuracy = 0.848544, accuracy_baseline = 0.7638036, auc = 0.914197, auc_precision_recall = 0.7847092, average_loss = 0.31906912, global_step = 2501, label/mean = 0.23619643, loss = 7686477.5, mirco_accuracy = 0.7049088, precision = 0.85184836, prediction/mean = 0.18851748, recall = 0.43430415\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2501: workspace/models/dnn_classifier/model.ckpt-2501\n",
      "INFO:tensorflow:Loss for final step: 8140835.0.\n",
      ".......................................\n",
      "Experiment finished.\n",
      "\n",
      "CPU times: user 2min 32s, sys: 17.3 s, total: 2min 49s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "estimator = create_estimator(params, run_config)\n",
    "\n",
    "early_stopping_hook = tf.estimator.experimental.stop_if_no_increase_hook(\n",
    "    estimator,\n",
    "    'accuracy',\n",
    "    max_steps_without_increase=100,\n",
    "    run_every_secs=None,\n",
    "    run_every_steps=500\n",
    ")\n",
    "\n",
    "%time run_experiment(estimator, params, run_config, train_hooks=[early_stopping_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export the Model for Serving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Implement a serving_input_receive_fn\n",
    "This function expect **raw** data interface, then it applies the **transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "def _serving_input_receiver_fn():\n",
    "    \n",
    "    source_raw_schema = tfdv.load_schema_text(RAW_SCHEMA_LOCATION)\n",
    "    raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "    raw_feature_spec.pop(TARGET_FEATURE_NAME)\n",
    "    raw_feature_spec.pop(WEIGHT_COLUMN_NAME)\n",
    "\n",
    "    # Create the interface for the serving function with the raw features\n",
    "    raw_features = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "        raw_feature_spec)().features\n",
    "\n",
    "    receiver_tensors = {\n",
    "        feature: tf.placeholder(shape=[None], dtype=raw_features[feature].dtype) \n",
    "        for feature in raw_features\n",
    "    }\n",
    "\n",
    "    receiver_tensors_expanded = {\n",
    "        tensor: tf.reshape(receiver_tensors[tensor], (-1, 1)) \n",
    "        for tensor in receiver_tensors\n",
    "    }\n",
    "\n",
    "    # Apply the transform function \n",
    "    transformed_features = transform_output.transform_raw_features(\n",
    "        receiver_tensors_expanded)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        transformed_features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Export SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'workspace/models/dnn_classifier/export/1581339146'\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "export_dir = os.path.join(MODEL_DIR, 'export')\n",
    "\n",
    "if tf.gfile.Exists(export_dir):\n",
    "    tf.gfile.DeleteRecursively(export_dir)\n",
    "        \n",
    "saved_model_location = estimator.export_savedmodel(\n",
    "    export_dir_base=export_dir,\n",
    "    serving_input_receiver_fn=_serving_input_receiver_fn\n",
    ")\n",
    "\n",
    "print(saved_model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['predict']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['age'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_9:0\n",
      "    inputs['capital_gain'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder:0\n",
      "    inputs['capital_loss'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_11:0\n",
      "    inputs['education'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_4:0\n",
      "    inputs['education_num'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_7:0\n",
      "    inputs['gender'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_3:0\n",
      "    inputs['hours_per_week'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_10:0\n",
      "    inputs['marital_status'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_2:0\n",
      "    inputs['native_country'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_8:0\n",
      "    inputs['occupation'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_6:0\n",
      "    inputs['race'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_12:0\n",
      "    inputs['relationship'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_1:0\n",
      "    inputs['workclass'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_5:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['all_class_ids'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1, 2)\n",
      "        name: head/predictions/Tile:0\n",
      "    outputs['all_classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 2)\n",
      "        name: head/predictions/Tile_1:0\n",
      "    outputs['class_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/ExpandDims:0\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/hash_table_Lookup/LookupTableFindV2:0\n",
      "    outputs['logistic'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/logistic:0\n",
      "    outputs['logits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: add:0\n",
      "    outputs['probabilities'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: head/predictions/probabilities:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir=${saved_model_location} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_class_ids': array([[0, 1]], dtype=int32),\n",
       " 'all_classes': array([[b' <=50K', b' >50K']], dtype=object),\n",
       " 'class_ids': array([[0]]),\n",
       " 'classes': array([[b' <=50K']], dtype=object),\n",
       " 'logistic': array([[0.10173763]], dtype=float32),\n",
       " 'logits': array([[-2.178065]], dtype=float32),\n",
       " 'probabilities': array([[0.8982623 , 0.10173761]], dtype=float32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "    export_dir = saved_model_location,\n",
    "    signature_def_key=\"predict\"\n",
    ")\n",
    "\n",
    "output = predictor_fn(\n",
    "    {\n",
    "        'age': [34.0],\n",
    "        'workclass': ['Private'],\n",
    "        'education': ['Doctorate'],\n",
    "        'education_num': [10.0],\n",
    "        'marital_status': ['Married-civ-spouse'],\n",
    "        'occupation': ['Prof-specialty'],\n",
    "        'relationship': ['Husband'],\n",
    "        'race': ['White'],\n",
    "        'gender': ['Male'],\n",
    "        'capital_gain': [0.0], \n",
    "        'capital_loss': [0.0], \n",
    "        'hours_per_week': [40.0],\n",
    "        'native_country':['England']\n",
    "    }\n",
    ")\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seralizing estimator object to be used in the following lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(estimator, './estimator.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q tensorflow-model-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Implement a serving_input_receive_fn\n",
    "This function expect **transform** data interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_receiver_fn():\n",
    "    \n",
    "    source_raw_schema = tfdv.load_schema_text(RAW_SCHEMA_LOCATION)\n",
    "    raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "    serving_input_receiver = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "        raw_feature_spec, default_batch_size=None)()\n",
    "    \n",
    "    features = serving_input_receiver.features.copy()\n",
    "    transformed_features = transform_output.transform_raw_features(features)\n",
    "\n",
    "    features.update(transformed_features)\n",
    "    \n",
    "    return tfma.export.EvalInputReceiver(\n",
    "        features=features,\n",
    "        receiver_tensors=serving_input_receiver.receiver_tensors,\n",
    "        labels=transformed_features[TARGET_FEATURE_NAME]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'workspace/models/dnn_classifier/export/evaluate/1581340469'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_dir = os.path.join(MODEL_DIR, \"export/evaluate\")\n",
    "if tf_io.gfile.exists(eval_model_dir):\n",
    "    tf_io.gfile.rmtree(eval_model_dir)\n",
    "\n",
    "tfma.export.export_eval_savedmodel(\n",
    "        estimator=estimator,\n",
    "        export_dir_base=eval_model_dir,\n",
    "        eval_input_receiver_fn=eval_input_receiver_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./estimator.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(estimator, './estimator.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'workspace/models/dnn_classifier/export/evaluate/1581340812'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = joblib.load( './estimator.joblib')\n",
    "tfma.export.export_eval_savedmodel(\n",
    "        estimator=e,\n",
    "        export_dir_base=eval_model_dir,\n",
    "        eval_input_receiver_fn=eval_input_receiver_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
