{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and Feature Engineering with TFT\n",
    "\n",
    "In this lab, we use [TensorFlow Transform](https://www.tensorflow.org/tfx/guide/tft) (TFT) to perform the following:\n",
    "\n",
    "1. **Implement** transformation logic in **preprocess_fn.\n",
    "2. **Implement** a Beam pipeline:\n",
    " 1. **Analyze** and **transform** training data.\n",
    " 2. **Transform** evaluation data.\n",
    "3. **Run** pipeline to produce the transformed **data** and transform **artifacts**.\n",
    "\n",
    "![alt text](imgs/tft.png \"Data transformation and feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q tensorflow_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.15.0\n",
      "TFDV version: 0.15.0\n",
      "TFT version: 0.15.0\n",
      "Apache Beam version: 2.16.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import apache_beam as beam\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "print('TF version: {}'.format(tf.__version__))\n",
    "print('TFDV version: {}'.format(tfdv.__version__))\n",
    "print('TFT version: {}'.format(tft.__version__))\n",
    "print('Apache Beam version: {}'.format(beam.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = 'workspace' # you can set to a GCS location\n",
    "DATA_DIR = os.path.join(WORKSPACE, 'raw_data')\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR,'train.csv')\n",
    "EVAL_DATA_FILE = os.path.join(DATA_DIR,'eval.csv')\n",
    "RAW_SCHEMA_LOCATION = os.path.join(WORKSPACE, 'raw_schema.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement transformation logic\n",
    "We make use of the raw schema to perform metadata-driven feature handling, as follows:\n",
    "1. Scale numeric features with z-score\n",
    "2. Integerise categorical features\n",
    "\n",
    "Ather transformations can be performed, including bucketization, polynomial expantion, clipping, or custom formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "          'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "          'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "          'native_country', 'income_bracket']\n",
    "TARGET_FEATURE_NAME = 'income_bracket'\n",
    "WEIGHT_COLUMN_NAME = 'fnlwgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessing_fn(raw_schema):\n",
    "        \n",
    "    def preprocessing_fn(input_features):\n",
    "        \n",
    "        processed_features = {}\n",
    "        \n",
    "        for feature in raw_schema.feature:\n",
    "            feature_name = feature.name\n",
    "\n",
    "            # Pass the target feature as is.\n",
    "            if feature_name == TARGET_FEATURE_NAME:\n",
    "                processed_features[feature_name] = input_features[feature_name]\n",
    "                continue\n",
    "\n",
    "            if feature.type == 1:\n",
    "                # Extract vocabulary and integerize categorical features.\n",
    "                processed_features[feature_name + \"_integerized\"] = tft.compute_and_apply_vocabulary(\n",
    "                    input_features[feature_name], vocab_filename=feature_name)\n",
    "            else:\n",
    "                # normalize numeric features.\n",
    "                processed_features[feature_name + \"_scaled\"] = tft.scale_to_z_score(\n",
    "                    input_features[feature_name])\n",
    "\n",
    "        # Pass the weight column\n",
    "        processed_features[WEIGHT_COLUMN_NAME] = input_features[WEIGHT_COLUMN_NAME]\n",
    "\n",
    "        # Bucketize age using quantiles. \n",
    "        quantiles = tft.quantiles(input_features[\"age\"], num_buckets=5, epsilon=0.01)\n",
    "        processed_features[\"age_bucketized\"] = tft.apply_buckets(\n",
    "          input_features[\"age\"], bucket_boundaries=quantiles)\n",
    "        \n",
    "        # Feature creation\n",
    "        education_to_age_ratio = input_features[\"age\"] / input_features[\"education_num\"]\n",
    "        capital_indicator = input_features['capital_gain'] > input_features['capital_loss']\n",
    "        processed_features['education_to_age_ratio'] = tf.cast(education_to_age_ratio, tf.float32)\n",
    "        processed_features['capital_indicator'] =tf.cast(capital_indicator, tf.int64)\n",
    "    \n",
    "        return processed_features\n",
    "\n",
    "    return preprocessing_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement a Beam pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(args):\n",
    "    \n",
    "    pipeline_options = beam.pipeline.PipelineOptions(flags=[], **args)\n",
    "    \n",
    "    raw_schema_location = args['raw_schema_location']\n",
    "    raw_train_data_location = args['raw_train_data_location']\n",
    "    raw_eval_data_location = args['raw_eval_data_location']\n",
    "    transformed_train_data_location = args['transformed_train_data_location']\n",
    "    transformed_eval_data_location = args['transformed_eval_data_location']\n",
    "    transform_artefact_location = args['transform_artefact_location']\n",
    "    temporary_dir = args['temporary_dir']\n",
    "    runner = args['runner']\n",
    "\n",
    "    # Load TFDV schema and create tft schema from it.\n",
    "    source_raw_schema = tfdv.load_schema_text(raw_schema_location)\n",
    "    raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "    \n",
    "    # Since the raw_feature_spec doesn't include the weight column, we need to add it. \n",
    "    raw_feature_spec[WEIGHT_COLUMN_NAME] = tf.FixedLenFeature(\n",
    "        shape=[1], dtype=tf.int64, default_value=None)\n",
    "    \n",
    "    raw_metadata = dataset_metadata.DatasetMetadata(\n",
    "      dataset_schema.from_feature_spec(raw_feature_spec))\n",
    "\n",
    "    with beam.Pipeline(runner, options=pipeline_options) as pipeline:\n",
    "        with tft_beam.Context(temporary_dir):\n",
    "            \n",
    "            converter = tft.coders.CsvCoder(column_names=HEADER, \n",
    "                schema=raw_metadata.schema)\n",
    "            \n",
    "            ###### analyze & transform trainining data ###############################\n",
    "\n",
    "            # Read raw training csv data.\n",
    "            step = 'Train'\n",
    "            \n",
    "            raw_train_data = (\n",
    "                pipeline\n",
    "                  | '{} - Read Raw Data'.format(step) >> beam.io.textio.ReadFromText(raw_train_data_location)\n",
    "                  | '{} - Remove Empty Rows'.format(step) >> beam.Filter(lambda line: line)\n",
    "                  | '{} - Decode CSV Data'.format(step) >> beam.Map(converter.decode)\n",
    "            )\n",
    "      \n",
    "            # Create a train dataset from the data and schema.\n",
    "            raw_train_dataset = (raw_train_data, raw_metadata)\n",
    "\n",
    "            # Analyze and transform raw_train_dataset to produced transformed_train_dataset and transform_fn.\n",
    "            transformed_train_dataset, transform_fn = (\n",
    "                raw_train_dataset \n",
    "                | '{} - Analyze & Transform'.format(step) >> tft_beam.AnalyzeAndTransformDataset(\n",
    "                      make_preprocessing_fn(source_raw_schema))\n",
    "            )\n",
    "  \n",
    "            # Get data and schema separately from the transformed_train_dataset.\n",
    "            transformed_train_data, transformed_metadata = transformed_train_dataset\n",
    "\n",
    "            # write transformed train data to sink.\n",
    "            _ = (\n",
    "                transformed_train_data \n",
    "                | '{} - Write Transformed Data'.format(step) >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "                    file_path_prefix=transformed_train_data_location,\n",
    "                    file_name_suffix=\".tfrecords\",\n",
    "                    coder=tft.coders.ExampleProtoCoder(transformed_metadata.schema))\n",
    "            )\n",
    "\n",
    "            ###### transform evaluation data #########################################\n",
    "\n",
    "            # Read raw training csv data.\n",
    "            step = 'Eval'\n",
    "\n",
    "            raw_eval_data = (\n",
    "            pipeline\n",
    "              | '{} - Read Raw Data'.format(step) >> beam.io.textio.ReadFromText(raw_eval_data_location)\n",
    "              | '{} - Remove Empty Rows'.format(step) >> beam.Filter(lambda line: line)\n",
    "              | '{} - Decode CSV Data'.format(step) >> beam.Map(converter.decode)\n",
    "            )\n",
    "      \n",
    "            # Create a eval dataset from the data and schema.\n",
    "            raw_eval_dataset = (raw_eval_data, raw_metadata)\n",
    "\n",
    "            # Transform eval data based on produced transform_fn.\n",
    "            transformed_eval_dataset = (\n",
    "                (raw_eval_dataset, transform_fn) \n",
    "                | '{} - Transform'.format(step) >> tft_beam.TransformDataset()\n",
    "            )\n",
    "\n",
    "            # Get data from the transformed_eval_dataset.\n",
    "            transformed_eval_data, _ = transformed_eval_dataset\n",
    "\n",
    "            # Write transformed eval data to sink.\n",
    "            _ = (\n",
    "                transformed_eval_data \n",
    "                | '{} - Write Transformed Data'.format(step) >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "                    file_path_prefix=transformed_eval_data_location,\n",
    "                    file_name_suffix=\".tfrecords\",\n",
    "                    coder=tft.coders.ExampleProtoCoder(transformed_metadata.schema))\n",
    "            )\n",
    "\n",
    "            ###### write transformation metadata #######################################################\n",
    "\n",
    "            # Write transform_fn.\n",
    "            _ = (\n",
    "              transform_fn \n",
    "              | 'Write Transform Artefacts' >> tft_beam.WriteTransformFn(\n",
    "                  transform_artefact_location)\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Data Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_ARTEFACTS_DIR = os.path.join(WORKSPACE,'transform_artifacts')\n",
    "TRANSFORMED_DATA_DIR = os.path.join(WORKSPACE,'transformed_data')\n",
    "TEMP_DIR = os.path.join(WORKSPACE, 'tmp')\n",
    "\n",
    "runner = 'DirectRunner'\n",
    "\n",
    "args = {\n",
    "    \n",
    "    'runner': runner,\n",
    "\n",
    "    'raw_schema_location': RAW_SCHEMA_LOCATION,\n",
    "\n",
    "    'raw_train_data_location': TRAIN_DATA_FILE,\n",
    "    'raw_eval_data_location': EVAL_DATA_FILE,\n",
    "\n",
    "    'transformed_train_data_location':  os.path.join(TRANSFORMED_DATA_DIR, \"train\"),\n",
    "    'transformed_eval_data_location':  os.path.join(TRANSFORMED_DATA_DIR, \"eval\"),\n",
    "    'transform_artefact_location':  TRANSFORM_ARTEFACTS_DIR,\n",
    "    \n",
    "    'temporary_dir': TEMP_DIR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing workspace/transformed_data contents...\n",
      "Removing workspace/transform_artifacts contents...\n",
      "Running TF Transform pipeline...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n",
      "WARNING:root:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.9 s, sys: 744 ms, total: 1min\n",
      "Wall time: 1min 2s\n",
      "\n",
      "Pipeline is done.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.io import gfile\n",
    "\n",
    "if gfile.exists(TEMP_DIR):\n",
    "    print(\"Removing {} contents...\".format(TEMP_DIR))\n",
    "    gfile.rmtree(TRANSFORMED_DATA_DIR)\n",
    "    \n",
    "if gfile.exists(TRANSFORMED_DATA_DIR):\n",
    "    print(\"Removing {} contents...\".format(TRANSFORMED_DATA_DIR))\n",
    "    gfile.rmtree(TRANSFORMED_DATA_DIR)\n",
    "          \n",
    "if gfile.exists(TRANSFORM_ARTEFACTS_DIR):\n",
    "    print(\"Removing {} contents...\".format(TRANSFORM_ARTEFACTS_DIR))\n",
    "    gfile.rmtree(TRANSFORM_ARTEFACTS_DIR)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(\"Running TF Transform pipeline...\")\n",
    "print(\"\")\n",
    "%time run_pipeline(args)\n",
    "print(\"\")\n",
    "print(\"Pipeline is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check TFT outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace/transform_artifacts/transform_fn:\n",
      "assets\tsaved_model.pb\tvariables\n",
      "\n",
      "workspace/transform_artifacts/transformed_metadata:\n",
      "schema.pbtxt\n"
     ]
    }
   ],
   "source": [
    "!ls {TRANSFORM_ARTEFACTS_DIR}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age_bucketized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'age_scaled': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'capital_gain_scaled': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'capital_indicator': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'capital_loss_scaled': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'education_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'education_num_scaled': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'education_to_age_ratio': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'fnlwgt': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'fnlwgt_scaled': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'gender_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'hours_per_week_scaled': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
       " 'income_bracket': FixedLenFeature(shape=[1], dtype=tf.string, default_value=None),\n",
       " 'marital_status_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'native_country_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'occupation_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'race_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'relationship_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None),\n",
       " 'workclass_integerized': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tft_output = tft.TFTransformOutput(TRANSFORM_ARTEFACTS_DIR)\n",
    "transform_feature_spec = tft_output.transformed_feature_spec()\n",
    "transform_feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital_indicator': <tf.Tensor: id=7633, shape=(1,), dtype=int64, numpy=array([1])>, 'education_integerized': <tf.Tensor: id=7635, shape=(1,), dtype=int64, numpy=array([2])>, 'gender_integerized': <tf.Tensor: id=7640, shape=(1,), dtype=int64, numpy=array([0])>, 'education_to_age_ratio': <tf.Tensor: id=7637, shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>, 'capital_loss_scaled': <tf.Tensor: id=7634, shape=(1,), dtype=float32, numpy=array([-0.21665958], dtype=float32)>, 'marital_status_integerized': <tf.Tensor: id=7643, shape=(1,), dtype=int64, numpy=array([1])>, 'capital_gain_scaled': <tf.Tensor: id=7632, shape=(1,), dtype=float32, numpy=array([0.14845291], dtype=float32)>, 'relationship_integerized': <tf.Tensor: id=7647, shape=(1,), dtype=int64, numpy=array([1])>, 'workclass_integerized': <tf.Tensor: id=7648, shape=(1,), dtype=int64, numpy=array([4])>, 'race_integerized': <tf.Tensor: id=7646, shape=(1,), dtype=int64, numpy=array([0])>, 'fnlwgt_scaled': <tf.Tensor: id=7639, shape=(1,), dtype=float32, numpy=array([-1.0636108], dtype=float32)>, 'fnlwgt': <tf.Tensor: id=7638, shape=(1,), dtype=int64, numpy=array([77516])>, 'age_bucketized': <tf.Tensor: id=7630, shape=(1,), dtype=int64, numpy=array([2])>, 'occupation_integerized': <tf.Tensor: id=7645, shape=(1,), dtype=int64, numpy=array([3])>, 'hours_per_week_scaled': <tf.Tensor: id=7641, shape=(1,), dtype=float32, numpy=array([-0.03542933], dtype=float32)>, 'age_scaled': <tf.Tensor: id=7631, shape=(1,), dtype=float32, numpy=array([0.03067062], dtype=float32)>, 'education_num_scaled': <tf.Tensor: id=7636, shape=(1,), dtype=float32, numpy=array([1.1347396], dtype=float32)>, 'native_country_integerized': <tf.Tensor: id=7644, shape=(1,), dtype=int64, numpy=array([0])>, 'income_bracket': <tf.Tensor: id=7642, shape=(1,), dtype=string, numpy=array([b' <=50K'], dtype=object)>}\n",
      "\n",
      "{'capital_indicator': <tf.Tensor: id=7652, shape=(1,), dtype=int64, numpy=array([0])>, 'education_integerized': <tf.Tensor: id=7654, shape=(1,), dtype=int64, numpy=array([2])>, 'gender_integerized': <tf.Tensor: id=7659, shape=(1,), dtype=int64, numpy=array([0])>, 'education_to_age_ratio': <tf.Tensor: id=7656, shape=(1,), dtype=float32, numpy=array([3.8461537], dtype=float32)>, 'capital_loss_scaled': <tf.Tensor: id=7653, shape=(1,), dtype=float32, numpy=array([-0.21665958], dtype=float32)>, 'marital_status_integerized': <tf.Tensor: id=7662, shape=(1,), dtype=int64, numpy=array([0])>, 'capital_gain_scaled': <tf.Tensor: id=7651, shape=(1,), dtype=float32, numpy=array([-0.14592049], dtype=float32)>, 'relationship_integerized': <tf.Tensor: id=7666, shape=(1,), dtype=int64, numpy=array([0])>, 'workclass_integerized': <tf.Tensor: id=7667, shape=(1,), dtype=int64, numpy=array([1])>, 'race_integerized': <tf.Tensor: id=7665, shape=(1,), dtype=int64, numpy=array([0])>, 'fnlwgt_scaled': <tf.Tensor: id=7658, shape=(1,), dtype=float32, numpy=array([-1.008707], dtype=float32)>, 'fnlwgt': <tf.Tensor: id=7657, shape=(1,), dtype=int64, numpy=array([83311])>, 'age_bucketized': <tf.Tensor: id=7649, shape=(1,), dtype=int64, numpy=array([4])>, 'occupation_integerized': <tf.Tensor: id=7664, shape=(1,), dtype=int64, numpy=array([2])>, 'hours_per_week_scaled': <tf.Tensor: id=7660, shape=(1,), dtype=float32, numpy=array([-2.222154], dtype=float32)>, 'age_scaled': <tf.Tensor: id=7650, shape=(1,), dtype=float32, numpy=array([0.8371091], dtype=float32)>, 'education_num_scaled': <tf.Tensor: id=7655, shape=(1,), dtype=float32, numpy=array([1.1347396], dtype=float32)>, 'native_country_integerized': <tf.Tensor: id=7663, shape=(1,), dtype=int64, numpy=array([0])>, 'income_bracket': <tf.Tensor: id=7661, shape=(1,), dtype=string, numpy=array([b' <=50K'], dtype=object)>}\n",
      "\n",
      "{'capital_indicator': <tf.Tensor: id=7671, shape=(1,), dtype=int64, numpy=array([0])>, 'education_integerized': <tf.Tensor: id=7673, shape=(1,), dtype=int64, numpy=array([0])>, 'gender_integerized': <tf.Tensor: id=7678, shape=(1,), dtype=int64, numpy=array([0])>, 'education_to_age_ratio': <tf.Tensor: id=7675, shape=(1,), dtype=float32, numpy=array([4.2222223], dtype=float32)>, 'capital_loss_scaled': <tf.Tensor: id=7672, shape=(1,), dtype=float32, numpy=array([-0.21665958], dtype=float32)>, 'marital_status_integerized': <tf.Tensor: id=7681, shape=(1,), dtype=int64, numpy=array([2])>, 'capital_gain_scaled': <tf.Tensor: id=7670, shape=(1,), dtype=float32, numpy=array([-0.14592049], dtype=float32)>, 'relationship_integerized': <tf.Tensor: id=7685, shape=(1,), dtype=int64, numpy=array([1])>, 'workclass_integerized': <tf.Tensor: id=7686, shape=(1,), dtype=int64, numpy=array([0])>, 'race_integerized': <tf.Tensor: id=7684, shape=(1,), dtype=int64, numpy=array([0])>, 'fnlwgt_scaled': <tf.Tensor: id=7677, shape=(1,), dtype=float32, numpy=array([0.24507841], dtype=float32)>, 'fnlwgt': <tf.Tensor: id=7676, shape=(1,), dtype=int64, numpy=array([215646])>, 'age_bucketized': <tf.Tensor: id=7668, shape=(1,), dtype=int64, numpy=array([2])>, 'occupation_integerized': <tf.Tensor: id=7683, shape=(1,), dtype=int64, numpy=array([9])>, 'hours_per_week_scaled': <tf.Tensor: id=7679, shape=(1,), dtype=float32, numpy=array([-0.03542933], dtype=float32)>, 'age_scaled': <tf.Tensor: id=7669, shape=(1,), dtype=float32, numpy=array([-0.04264197], dtype=float32)>, 'education_num_scaled': <tf.Tensor: id=7674, shape=(1,), dtype=float32, numpy=array([-0.42005974], dtype=float32)>, 'native_country_integerized': <tf.Tensor: id=7682, shape=(1,), dtype=int64, numpy=array([0])>, 'income_bracket': <tf.Tensor: id=7680, shape=(1,), dtype=string, numpy=array([b' <=50K'], dtype=object)>}\n",
      "\n",
      "{'capital_indicator': <tf.Tensor: id=7690, shape=(1,), dtype=int64, numpy=array([0])>, 'education_integerized': <tf.Tensor: id=7692, shape=(1,), dtype=int64, numpy=array([5])>, 'gender_integerized': <tf.Tensor: id=7697, shape=(1,), dtype=int64, numpy=array([0])>, 'education_to_age_ratio': <tf.Tensor: id=7694, shape=(1,), dtype=float32, numpy=array([7.571429], dtype=float32)>, 'capital_loss_scaled': <tf.Tensor: id=7691, shape=(1,), dtype=float32, numpy=array([-0.21665958], dtype=float32)>, 'marital_status_integerized': <tf.Tensor: id=7700, shape=(1,), dtype=int64, numpy=array([0])>, 'capital_gain_scaled': <tf.Tensor: id=7689, shape=(1,), dtype=float32, numpy=array([-0.14592049], dtype=float32)>, 'relationship_integerized': <tf.Tensor: id=7704, shape=(1,), dtype=int64, numpy=array([0])>, 'workclass_integerized': <tf.Tensor: id=7705, shape=(1,), dtype=int64, numpy=array([0])>, 'race_integerized': <tf.Tensor: id=7703, shape=(1,), dtype=int64, numpy=array([1])>, 'fnlwgt_scaled': <tf.Tensor: id=7696, shape=(1,), dtype=float32, numpy=array([0.42580125], dtype=float32)>, 'fnlwgt': <tf.Tensor: id=7695, shape=(1,), dtype=int64, numpy=array([234721])>, 'age_bucketized': <tf.Tensor: id=7687, shape=(1,), dtype=int64, numpy=array([4])>, 'occupation_integerized': <tf.Tensor: id=7702, shape=(1,), dtype=int64, numpy=array([9])>, 'hours_per_week_scaled': <tf.Tensor: id=7698, shape=(1,), dtype=float32, numpy=array([-0.03542933], dtype=float32)>, 'age_scaled': <tf.Tensor: id=7688, shape=(1,), dtype=float32, numpy=array([1.0570469], dtype=float32)>, 'education_num_scaled': <tf.Tensor: id=7693, shape=(1,), dtype=float32, numpy=array([-1.1974595], dtype=float32)>, 'native_country_integerized': <tf.Tensor: id=7701, shape=(1,), dtype=int64, numpy=array([0])>, 'income_bracket': <tf.Tensor: id=7699, shape=(1,), dtype=string, numpy=array([b' <=50K'], dtype=object)>}\n",
      "\n",
      "{'capital_indicator': <tf.Tensor: id=7709, shape=(1,), dtype=int64, numpy=array([0])>, 'education_integerized': <tf.Tensor: id=7711, shape=(1,), dtype=int64, numpy=array([2])>, 'gender_integerized': <tf.Tensor: id=7716, shape=(1,), dtype=int64, numpy=array([1])>, 'education_to_age_ratio': <tf.Tensor: id=7713, shape=(1,), dtype=float32, numpy=array([2.1538463], dtype=float32)>, 'capital_loss_scaled': <tf.Tensor: id=7710, shape=(1,), dtype=float32, numpy=array([-0.21665958], dtype=float32)>, 'marital_status_integerized': <tf.Tensor: id=7719, shape=(1,), dtype=int64, numpy=array([0])>, 'capital_gain_scaled': <tf.Tensor: id=7708, shape=(1,), dtype=float32, numpy=array([-0.14592049], dtype=float32)>, 'relationship_integerized': <tf.Tensor: id=7723, shape=(1,), dtype=int64, numpy=array([4])>, 'workclass_integerized': <tf.Tensor: id=7724, shape=(1,), dtype=int64, numpy=array([0])>, 'race_integerized': <tf.Tensor: id=7722, shape=(1,), dtype=int64, numpy=array([1])>, 'fnlwgt_scaled': <tf.Tensor: id=7715, shape=(1,), dtype=float32, numpy=array([1.4081756], dtype=float32)>, 'fnlwgt': <tf.Tensor: id=7714, shape=(1,), dtype=int64, numpy=array([338409])>, 'age_bucketized': <tf.Tensor: id=7706, shape=(1,), dtype=int64, numpy=array([1])>, 'occupation_integerized': <tf.Tensor: id=7721, shape=(1,), dtype=int64, numpy=array([0])>, 'hours_per_week_scaled': <tf.Tensor: id=7717, shape=(1,), dtype=float32, numpy=array([-0.03542933], dtype=float32)>, 'age_scaled': <tf.Tensor: id=7707, shape=(1,), dtype=float32, numpy=array([-0.77576786], dtype=float32)>, 'education_num_scaled': <tf.Tensor: id=7712, shape=(1,), dtype=float32, numpy=array([1.1347396], dtype=float32)>, 'native_country_integerized': <tf.Tensor: id=7720, shape=(1,), dtype=int64, numpy=array([9])>, 'income_bracket': <tf.Tensor: id=7718, shape=(1,), dtype=string, numpy=array([b' <=50K'], dtype=object)>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _parse_example(example):\n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example, transform_feature_spec)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(TRANSFORMED_DATA_DIR + \"/train-00000-of-00001.tfrecords\")\n",
    "for record in dataset.take(5).map(_parse_example):\n",
    "    print(record)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
